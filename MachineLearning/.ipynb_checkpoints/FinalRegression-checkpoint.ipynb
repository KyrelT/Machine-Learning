{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d40af0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv \n",
    "import sklearn\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from numpy import mean, std, absolute\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, KFold\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "from sklearn.svm import SVR\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7ff8f6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\anaconda3\\envs\\mle_tf\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df= pd.read_excel('RealEstateDataset.xlsx', sheet_name ='Data', usecols = 'B:H')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "438aaa98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing\n",
    "df = df.rename(columns={\"X1 transaction date\":\"trans_date\",\"X2 house age\":\"house_age\", \"X3 distance to the nearest MRT station\":\"mrt_distance\",\"X4 number of convenience stores\":\"no_convenience_stores\", \"X5 latitude\" : \"latitude\" , \"X6 longitude\":\"longitude\", \"Y house price of unit area\" : \"house_price_PA\" })\n",
    "df.dropna()\n",
    "\n",
    "X = df.drop('trans_date', axis = 1)\n",
    "X = df.iloc[:,:-1]\n",
    "y  = df.iloc[:, -1]\n",
    "\n",
    "#Feature normalisation (Linear Regression and Multi-layer Perceptron Neural Network)\n",
    "sc = StandardScaler()\n",
    "scaled_X = sc.fit_transform(X)\n",
    "x_train, x_test, y_train, y_test = train_test_split(scaled_X,y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "#Feature normalisation (Support Vector Machine Regression and Decision Tree Regression)\n",
    "y = y.values.reshape(414,1)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size = 0.2, random_state=42)\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test= sc.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac6c380",
   "metadata": {},
   "source": [
    "Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6069d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear regression model \n",
    "LR = LinearRegression()\n",
    "# fitting the training data\n",
    "LR.fit(x_train,y_train)\n",
    "\n",
    "# 5 fold \n",
    "n_folds = 5\n",
    "lr= LinearRegression()\n",
    "cv_error = np.average(cross_val_score(lr, scaled_X, y,scoring='neg_mean_squared_error', cv=n_folds))\n",
    "print('The {}-fold cross-validation mean squared error for this regression model is {:.2f}'.format(n_folds, abs(cv_error)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b55e3919",
   "metadata": {},
   "source": [
    "Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9870cd8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Support Vector Machine Regression Model\n",
    "pre_svr_model = SVR(kernel='rbf',gamma='scale')\n",
    "pre_svr_model.fit(X_train,np.ravel(Y_train))\n",
    "pre_svr_model_pred = pre_svr_model.predict(X_test)\n",
    "\n",
    "print('Mean Squared Error before parameter tuning {:.2f}'.format(MSE(Y_test,pre_svr_model_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683e786d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(Y_test-pre_svr_model_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ed513a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(Y_test,pre_svr_model_pred)\n",
    "plt.plot(pre_svr_model_pred, pre_svr_model.predict(X_test),color = 'red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c15e12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameter tuning for support vector machine\n",
    "SVR_param_grid = {'C':[0.01, 0.1, 1,10],'kernel':['linear','rbf'],'gamma':[0.001,0.01,0.1,1,10], 'epsilon':[0.01,0.1,1,10]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c3b6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find the best parameters\n",
    "svr_cv = KFold(n_splits = 5)\n",
    "svr_grid = GridSearchCV(SVR(), SVR_param_grid, cv=svr_cv, scoring='neg_mean_squared_error')\n",
    "svr_grid.fit(X_train, np.ravel(Y_train))\n",
    "\n",
    "#Summarize results\n",
    "print(\"Best params for SVR: \", svr_grid.best_params_)\n",
    "print(\"Best score for SVR: \", absolute(svr_grid.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e27ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After getting the best parameters \n",
    "post_svr_model = SVR(C=10,epsilon = 1, gamma = 0.1, kernel = 'rbf')\n",
    "post_svr_model.fit(X_train, np.ravel(Y_train))\n",
    "post_svr_pred = post_svr_model.predict(X_test)\n",
    "print('Mean Squared Error after parameter tuning: {:.2f}' .format(MSE(Y_test, post_svr_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909865f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(Y_test,post_svr_pred)\n",
    "plt.plot(post_svr_pred, post_svr_model.predict(X_test), color = 'green')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4501740c",
   "metadata": {},
   "source": [
    "Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489e2a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree Regression Model\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size = 0.2, random_state=42)\n",
    "pre_tree_model = DecisionTreeRegressor()\n",
    "pre_tree_model.fit(X_train, Y_train)\n",
    "pre_tree_pred = pre_tree_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f820ca04",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(Y_test-pre_tree_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8539f9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(Y_test,pre_tree_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2509738",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameter tuning for decision tree\n",
    "\n",
    "param = {\n",
    "    'splitter': ['best','random'],\n",
    "    'max_depth': [1,3,5,7,9,11,12],\n",
    "    'min_samples_leaf': [1,2,3,4,5,6,7,8,9,10],\n",
    "    'min_weight_fraction_leaf':[0.1,0.2,0.3,0.4,0.5],\n",
    "    'max_features':[\"auto\",\"log2\",\"sqrt\",None],\n",
    "    'max_leaf_nodes':[None,10,20,30,40,50,60,70,80,90]\n",
    "        }\n",
    "\n",
    "#define grid search\n",
    "tree_grid = GridSearchCV(pre_tree_model, param_grid = param, cv = 5,n_jobs = -1, verbose = 3, scoring = 'neg_mean_squared_error' )\n",
    "tree_grid.fit(X_train,Y_train)\n",
    "\n",
    "#Summarize Results\n",
    "print('Decision Tree best Params:', tree_grid.best_params_)\n",
    "print('Decision Tree best Score:', tree_grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b322cb23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After getting the best parameters\n",
    "DTreg = DecisionTreeRegressor(criterion = 'squared_error',max_depth = 3, min_samples_leaf = 1,max_features = 'auto',max_leaf_nodes = 50, min_weight_fraction_leaf = 0.1, splitter = 'best')\n",
    "DTreg.fit(X_train,Y_train)\n",
    "post_tree_pred = DTreg.predict(X_test)\n",
    "print('mean_squared_error : {:.2f} '.format(MSE(Y_test,post_tree_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b5a48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(Y_test,post_tree_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a326fd",
   "metadata": {},
   "source": [
    "Perceptron Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6862a012",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\anaconda3\\envs\\mle_tf\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "5 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Asus\\anaconda3\\envs\\mle_tf\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Asus\\anaconda3\\envs\\mle_tf\\lib\\site-packages\\tensorflow\\python\\keras\\wrappers\\scikit_learn.py\", line 159, in fit\n",
      "    if (losses.is_categorical_crossentropy(self.model.loss) and\n",
      "AttributeError: 'NoneType' object has no attribute 'loss'\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\Asus\\anaconda3\\envs\\mle_tf\\lib\\site-packages\\sklearn\\model_selection\\_search.py:972: UserWarning: One or more of the test scores are non-finite: [ -91.09784622  -94.88507209  -89.25602331           nan  -85.14150722\n",
      "  -80.25765073  -84.87721825  -85.47798679  -91.77934568  -85.48179479\n",
      " -354.93581709  -90.2362871 ]\n",
      "  category=UserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "331/331 [==============================] - 0s 247us/sample - loss: 1805.9702 - mean_squared_error: 1805.9702\n",
      "Epoch 2/200\n",
      "331/331 [==============================] - 0s 52us/sample - loss: 1790.3954 - mean_squared_error: 1790.3954\n",
      "Epoch 3/200\n",
      "331/331 [==============================] - 0s 44us/sample - loss: 1775.7009 - mean_squared_error: 1775.7009\n",
      "Epoch 4/200\n",
      "331/331 [==============================] - 0s 36us/sample - loss: 1762.9057 - mean_squared_error: 1762.9054\n",
      "Epoch 5/200\n",
      "331/331 [==============================] - 0s 50us/sample - loss: 1750.6324 - mean_squared_error: 1750.6326\n",
      "Epoch 6/200\n",
      "331/331 [==============================] - 0s 47us/sample - loss: 1739.2736 - mean_squared_error: 1739.2738\n",
      "Epoch 7/200\n",
      "331/331 [==============================] - 0s 49us/sample - loss: 1729.0225 - mean_squared_error: 1729.0225\n",
      "Epoch 8/200\n",
      "331/331 [==============================] - 0s 39us/sample - loss: 1719.7308 - mean_squared_error: 1719.7307\n",
      "Epoch 9/200\n",
      "331/331 [==============================] - 0s 39us/sample - loss: 1710.5493 - mean_squared_error: 1710.5491\n",
      "Epoch 10/200\n",
      "331/331 [==============================] - 0s 39us/sample - loss: 1702.0819 - mean_squared_error: 1702.0818\n",
      "Epoch 11/200\n",
      "331/331 [==============================] - 0s 36us/sample - loss: 1693.7468 - mean_squared_error: 1693.7466\n",
      "Epoch 12/200\n",
      "331/331 [==============================] - 0s 42us/sample - loss: 1686.4365 - mean_squared_error: 1686.4365\n",
      "Epoch 13/200\n",
      "331/331 [==============================] - 0s 42us/sample - loss: 1679.1760 - mean_squared_error: 1679.1760\n",
      "Epoch 14/200\n",
      "331/331 [==============================] - 0s 47us/sample - loss: 1671.8319 - mean_squared_error: 1671.8322\n",
      "Epoch 15/200\n",
      "331/331 [==============================] - 0s 36us/sample - loss: 1664.2355 - mean_squared_error: 1664.2355\n",
      "Epoch 16/200\n",
      "331/331 [==============================] - 0s 45us/sample - loss: 1656.5430 - mean_squared_error: 1656.5432\n",
      "Epoch 17/200\n",
      "331/331 [==============================] - 0s 42us/sample - loss: 1648.5104 - mean_squared_error: 1648.5104\n",
      "Epoch 18/200\n",
      "331/331 [==============================] - 0s 46us/sample - loss: 1640.7077 - mean_squared_error: 1640.7078\n",
      "Epoch 19/200\n",
      "331/331 [==============================] - 0s 39us/sample - loss: 1632.8105 - mean_squared_error: 1632.8104\n",
      "Epoch 20/200\n",
      "331/331 [==============================] - 0s 31us/sample - loss: 1624.4648 - mean_squared_error: 1624.4648\n",
      "Epoch 21/200\n",
      "331/331 [==============================] - 0s 49us/sample - loss: 1615.6779 - mean_squared_error: 1615.6779\n",
      "Epoch 22/200\n",
      "331/331 [==============================] - 0s 53us/sample - loss: 1606.7984 - mean_squared_error: 1606.7983\n",
      "Epoch 23/200\n",
      "331/331 [==============================] - 0s 39us/sample - loss: 1597.6084 - mean_squared_error: 1597.6084\n",
      "Epoch 24/200\n",
      "331/331 [==============================] - 0s 52us/sample - loss: 1588.1975 - mean_squared_error: 1588.1975\n",
      "Epoch 25/200\n",
      "331/331 [==============================] - 0s 40us/sample - loss: 1578.7686 - mean_squared_error: 1578.7686\n",
      "Epoch 26/200\n",
      "331/331 [==============================] - 0s 37us/sample - loss: 1568.7178 - mean_squared_error: 1568.7178\n",
      "Epoch 27/200\n",
      "331/331 [==============================] - 0s 41us/sample - loss: 1558.0373 - mean_squared_error: 1558.0374\n",
      "Epoch 28/200\n",
      "331/331 [==============================] - 0s 39us/sample - loss: 1546.2529 - mean_squared_error: 1546.2528\n",
      "Epoch 29/200\n",
      "331/331 [==============================] - 0s 44us/sample - loss: 1533.5033 - mean_squared_error: 1533.5033\n",
      "Epoch 30/200\n",
      "331/331 [==============================] - 0s 36us/sample - loss: 1520.0953 - mean_squared_error: 1520.0953\n",
      "Epoch 31/200\n",
      "331/331 [==============================] - 0s 47us/sample - loss: 1506.1957 - mean_squared_error: 1506.1957\n",
      "Epoch 32/200\n",
      "331/331 [==============================] - 0s 35us/sample - loss: 1491.3388 - mean_squared_error: 1491.3390\n",
      "Epoch 33/200\n",
      "331/331 [==============================] - 0s 60us/sample - loss: 1476.3330 - mean_squared_error: 1476.3330\n",
      "Epoch 34/200\n",
      "331/331 [==============================] - 0s 40us/sample - loss: 1461.0615 - mean_squared_error: 1461.0614\n",
      "Epoch 35/200\n",
      "331/331 [==============================] - 0s 54us/sample - loss: 1444.3578 - mean_squared_error: 1444.3577\n",
      "Epoch 36/200\n",
      "331/331 [==============================] - 0s 51us/sample - loss: 1426.0382 - mean_squared_error: 1426.0382\n",
      "Epoch 37/200\n",
      "331/331 [==============================] - 0s 51us/sample - loss: 1406.6951 - mean_squared_error: 1406.6951\n",
      "Epoch 38/200\n",
      "331/331 [==============================] - 0s 124us/sample - loss: 1387.1234 - mean_squared_error: 1387.1235\n",
      "Epoch 39/200\n",
      "331/331 [==============================] - 0s 56us/sample - loss: 1367.0685 - mean_squared_error: 1367.0685\n",
      "Epoch 40/200\n",
      "331/331 [==============================] - 0s 45us/sample - loss: 1345.3475 - mean_squared_error: 1345.3475\n",
      "Epoch 41/200\n",
      "331/331 [==============================] - 0s 76us/sample - loss: 1322.8884 - mean_squared_error: 1322.8884\n",
      "Epoch 42/200\n",
      "331/331 [==============================] - 0s 46us/sample - loss: 1299.6614 - mean_squared_error: 1299.6614\n",
      "Epoch 43/200\n",
      "331/331 [==============================] - 0s 42us/sample - loss: 1275.9735 - mean_squared_error: 1275.9735\n",
      "Epoch 44/200\n",
      "331/331 [==============================] - 0s 48us/sample - loss: 1251.2287 - mean_squared_error: 1251.2288\n",
      "Epoch 45/200\n",
      "331/331 [==============================] - 0s 33us/sample - loss: 1226.2188 - mean_squared_error: 1226.2189\n",
      "Epoch 46/200\n",
      "331/331 [==============================] - 0s 64us/sample - loss: 1196.5237 - mean_squared_error: 1196.5237\n",
      "Epoch 47/200\n",
      "331/331 [==============================] - 0s 47us/sample - loss: 1166.8498 - mean_squared_error: 1166.8497\n",
      "Epoch 48/200\n",
      "331/331 [==============================] - 0s 59us/sample - loss: 1137.7028 - mean_squared_error: 1137.7028\n",
      "Epoch 49/200\n",
      "331/331 [==============================] - 0s 85us/sample - loss: 1108.8299 - mean_squared_error: 1108.8298\n",
      "Epoch 50/200\n",
      "331/331 [==============================] - 0s 72us/sample - loss: 1078.9448 - mean_squared_error: 1078.9448\n",
      "Epoch 51/200\n",
      "331/331 [==============================] - 0s 72us/sample - loss: 1047.9877 - mean_squared_error: 1047.9877\n",
      "Epoch 52/200\n",
      "331/331 [==============================] - 0s 45us/sample - loss: 1016.8418 - mean_squared_error: 1016.8419\n",
      "Epoch 53/200\n",
      "331/331 [==============================] - 0s 71us/sample - loss: 985.0484 - mean_squared_error: 985.0485\n",
      "Epoch 54/200\n",
      "331/331 [==============================] - 0s 43us/sample - loss: 951.8916 - mean_squared_error: 951.8916\n",
      "Epoch 55/200\n",
      "331/331 [==============================] - 0s 47us/sample - loss: 916.5537 - mean_squared_error: 916.5537\n",
      "Epoch 56/200\n",
      "331/331 [==============================] - 0s 44us/sample - loss: 882.8357 - mean_squared_error: 882.8356\n",
      "Epoch 57/200\n",
      "331/331 [==============================] - 0s 40us/sample - loss: 850.3837 - mean_squared_error: 850.3837\n",
      "Epoch 58/200\n",
      "331/331 [==============================] - 0s 55us/sample - loss: 817.4680 - mean_squared_error: 817.4681\n",
      "Epoch 59/200\n",
      "331/331 [==============================] - 0s 48us/sample - loss: 786.3517 - mean_squared_error: 786.3517\n",
      "Epoch 60/200\n",
      "331/331 [==============================] - 0s 53us/sample - loss: 754.1509 - mean_squared_error: 754.1509\n",
      "Epoch 61/200\n",
      "331/331 [==============================] - 0s 46us/sample - loss: 722.7495 - mean_squared_error: 722.7495\n",
      "Epoch 62/200\n",
      "331/331 [==============================] - 0s 61us/sample - loss: 690.1411 - mean_squared_error: 690.1411\n",
      "Epoch 63/200\n",
      "331/331 [==============================] - 0s 63us/sample - loss: 658.3110 - mean_squared_error: 658.3110\n",
      "Epoch 64/200\n",
      "331/331 [==============================] - 0s 52us/sample - loss: 626.6909 - mean_squared_error: 626.6909\n",
      "Epoch 65/200\n",
      "331/331 [==============================] - 0s 59us/sample - loss: 594.2229 - mean_squared_error: 594.2229\n",
      "Epoch 66/200\n",
      "331/331 [==============================] - 0s 46us/sample - loss: 563.2210 - mean_squared_error: 563.2209\n",
      "Epoch 67/200\n",
      "331/331 [==============================] - 0s 53us/sample - loss: 533.3434 - mean_squared_error: 533.3434\n",
      "Epoch 68/200\n",
      "331/331 [==============================] - 0s 58us/sample - loss: 504.4988 - mean_squared_error: 504.4988\n",
      "Epoch 69/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "331/331 [==============================] - 0s 47us/sample - loss: 477.5465 - mean_squared_error: 477.5465\n",
      "Epoch 70/200\n",
      "331/331 [==============================] - 0s 56us/sample - loss: 452.6640 - mean_squared_error: 452.6640\n",
      "Epoch 71/200\n",
      "331/331 [==============================] - 0s 43us/sample - loss: 429.2124 - mean_squared_error: 429.2124\n",
      "Epoch 72/200\n",
      "331/331 [==============================] - 0s 76us/sample - loss: 406.7920 - mean_squared_error: 406.7920\n",
      "Epoch 73/200\n",
      "331/331 [==============================] - 0s 67us/sample - loss: 385.9398 - mean_squared_error: 385.9398\n",
      "Epoch 74/200\n",
      "331/331 [==============================] - 0s 66us/sample - loss: 365.7140 - mean_squared_error: 365.7140\n",
      "Epoch 75/200\n",
      "331/331 [==============================] - 0s 53us/sample - loss: 347.0115 - mean_squared_error: 347.0116\n",
      "Epoch 76/200\n",
      "331/331 [==============================] - 0s 68us/sample - loss: 330.0108 - mean_squared_error: 330.0107\n",
      "Epoch 77/200\n",
      "331/331 [==============================] - 0s 72us/sample - loss: 314.3691 - mean_squared_error: 314.3690\n",
      "Epoch 78/200\n",
      "331/331 [==============================] - 0s 52us/sample - loss: 300.0175 - mean_squared_error: 300.0175\n",
      "Epoch 79/200\n",
      "331/331 [==============================] - 0s 65us/sample - loss: 286.3441 - mean_squared_error: 286.3441\n",
      "Epoch 80/200\n",
      "331/331 [==============================] - 0s 63us/sample - loss: 274.2026 - mean_squared_error: 274.2027\n",
      "Epoch 81/200\n",
      "331/331 [==============================] - 0s 52us/sample - loss: 262.8753 - mean_squared_error: 262.8753\n",
      "Epoch 82/200\n",
      "331/331 [==============================] - 0s 52us/sample - loss: 252.2769 - mean_squared_error: 252.2769\n",
      "Epoch 83/200\n",
      "331/331 [==============================] - 0s 61us/sample - loss: 242.7625 - mean_squared_error: 242.7625\n",
      "Epoch 84/200\n",
      "331/331 [==============================] - 0s 63us/sample - loss: 234.5707 - mean_squared_error: 234.5707\n",
      "Epoch 85/200\n",
      "331/331 [==============================] - 0s 59us/sample - loss: 226.3926 - mean_squared_error: 226.3927\n",
      "Epoch 86/200\n",
      "331/331 [==============================] - 0s 60us/sample - loss: 218.7006 - mean_squared_error: 218.7006\n",
      "Epoch 87/200\n",
      "331/331 [==============================] - 0s 49us/sample - loss: 210.9944 - mean_squared_error: 210.9944\n",
      "Epoch 88/200\n",
      "331/331 [==============================] - 0s 62us/sample - loss: 203.6675 - mean_squared_error: 203.6675\n",
      "Epoch 89/200\n",
      "331/331 [==============================] - 0s 43us/sample - loss: 197.3621 - mean_squared_error: 197.3621\n",
      "Epoch 90/200\n",
      "331/331 [==============================] - 0s 54us/sample - loss: 192.1518 - mean_squared_error: 192.1518\n",
      "Epoch 91/200\n",
      "331/331 [==============================] - 0s 60us/sample - loss: 186.8504 - mean_squared_error: 186.8504\n",
      "Epoch 92/200\n",
      "331/331 [==============================] - 0s 53us/sample - loss: 182.4551 - mean_squared_error: 182.4551\n",
      "Epoch 93/200\n",
      "331/331 [==============================] - 0s 52us/sample - loss: 178.2827 - mean_squared_error: 178.2827\n",
      "Epoch 94/200\n",
      "331/331 [==============================] - 0s 62us/sample - loss: 174.4825 - mean_squared_error: 174.4825\n",
      "Epoch 95/200\n",
      "331/331 [==============================] - 0s 51us/sample - loss: 170.7523 - mean_squared_error: 170.7523\n",
      "Epoch 96/200\n",
      "331/331 [==============================] - 0s 53us/sample - loss: 167.1287 - mean_squared_error: 167.1287\n",
      "Epoch 97/200\n",
      "331/331 [==============================] - 0s 48us/sample - loss: 163.9666 - mean_squared_error: 163.9666\n",
      "Epoch 98/200\n",
      "331/331 [==============================] - 0s 58us/sample - loss: 160.9819 - mean_squared_error: 160.9819\n",
      "Epoch 99/200\n",
      "331/331 [==============================] - 0s 56us/sample - loss: 157.9687 - mean_squared_error: 157.9687\n",
      "Epoch 100/200\n",
      "331/331 [==============================] - 0s 45us/sample - loss: 155.1771 - mean_squared_error: 155.1771\n",
      "Epoch 101/200\n",
      "331/331 [==============================] - 0s 61us/sample - loss: 152.0610 - mean_squared_error: 152.0610\n",
      "Epoch 102/200\n",
      "331/331 [==============================] - 0s 44us/sample - loss: 149.5497 - mean_squared_error: 149.5497\n",
      "Epoch 103/200\n",
      "331/331 [==============================] - 0s 59us/sample - loss: 147.3794 - mean_squared_error: 147.3793\n",
      "Epoch 104/200\n",
      "331/331 [==============================] - 0s 54us/sample - loss: 145.4848 - mean_squared_error: 145.4848\n",
      "Epoch 105/200\n",
      "331/331 [==============================] - 0s 45us/sample - loss: 143.1475 - mean_squared_error: 143.1475\n",
      "Epoch 106/200\n",
      "331/331 [==============================] - 0s 59us/sample - loss: 140.6927 - mean_squared_error: 140.6927\n",
      "Epoch 107/200\n",
      "331/331 [==============================] - 0s 51us/sample - loss: 138.8247 - mean_squared_error: 138.8247\n",
      "Epoch 108/200\n",
      "331/331 [==============================] - 0s 61us/sample - loss: 136.9442 - mean_squared_error: 136.9442\n",
      "Epoch 109/200\n",
      "331/331 [==============================] - 0s 57us/sample - loss: 134.9302 - mean_squared_error: 134.9302\n",
      "Epoch 110/200\n",
      "331/331 [==============================] - 0s 44us/sample - loss: 133.1304 - mean_squared_error: 133.1304\n",
      "Epoch 111/200\n",
      "331/331 [==============================] - 0s 55us/sample - loss: 131.1322 - mean_squared_error: 131.1322\n",
      "Epoch 112/200\n",
      "331/331 [==============================] - 0s 43us/sample - loss: 129.3584 - mean_squared_error: 129.3584\n",
      "Epoch 113/200\n",
      "331/331 [==============================] - 0s 60us/sample - loss: 127.9468 - mean_squared_error: 127.9468\n",
      "Epoch 114/200\n",
      "331/331 [==============================] - 0s 49us/sample - loss: 126.5600 - mean_squared_error: 126.5600\n",
      "Epoch 115/200\n",
      "331/331 [==============================] - 0s 54us/sample - loss: 125.2849 - mean_squared_error: 125.2849\n",
      "Epoch 116/200\n",
      "331/331 [==============================] - 0s 45us/sample - loss: 123.9932 - mean_squared_error: 123.9932\n",
      "Epoch 117/200\n",
      "331/331 [==============================] - 0s 46us/sample - loss: 122.5227 - mean_squared_error: 122.5227\n",
      "Epoch 118/200\n",
      "331/331 [==============================] - 0s 47us/sample - loss: 121.1523 - mean_squared_error: 121.1523\n",
      "Epoch 119/200\n",
      "331/331 [==============================] - 0s 49us/sample - loss: 120.0877 - mean_squared_error: 120.0877\n",
      "Epoch 120/200\n",
      "331/331 [==============================] - 0s 60us/sample - loss: 118.9375 - mean_squared_error: 118.9375\n",
      "Epoch 121/200\n",
      "331/331 [==============================] - 0s 53us/sample - loss: 117.9055 - mean_squared_error: 117.9055\n",
      "Epoch 122/200\n",
      "331/331 [==============================] - 0s 76us/sample - loss: 116.9073 - mean_squared_error: 116.9073\n",
      "Epoch 123/200\n",
      "331/331 [==============================] - 0s 59us/sample - loss: 115.8167 - mean_squared_error: 115.8167\n",
      "Epoch 124/200\n",
      "331/331 [==============================] - 0s 73us/sample - loss: 114.7936 - mean_squared_error: 114.7936\n",
      "Epoch 125/200\n",
      "331/331 [==============================] - 0s 57us/sample - loss: 113.8765 - mean_squared_error: 113.8765\n",
      "Epoch 126/200\n",
      "331/331 [==============================] - 0s 57us/sample - loss: 112.9641 - mean_squared_error: 112.9641\n",
      "Epoch 127/200\n",
      "331/331 [==============================] - 0s 75us/sample - loss: 112.0681 - mean_squared_error: 112.0681\n",
      "Epoch 128/200\n",
      "331/331 [==============================] - 0s 88us/sample - loss: 111.0923 - mean_squared_error: 111.0923\n",
      "Epoch 129/200\n",
      "331/331 [==============================] - 0s 79us/sample - loss: 110.1402 - mean_squared_error: 110.1402\n",
      "Epoch 130/200\n",
      "331/331 [==============================] - 0s 59us/sample - loss: 109.2567 - mean_squared_error: 109.2567\n",
      "Epoch 131/200\n",
      "331/331 [==============================] - 0s 63us/sample - loss: 108.2938 - mean_squared_error: 108.2938\n",
      "Epoch 132/200\n",
      "331/331 [==============================] - 0s 48us/sample - loss: 107.5073 - mean_squared_error: 107.5073\n",
      "Epoch 133/200\n",
      "331/331 [==============================] - 0s 41us/sample - loss: 106.5849 - mean_squared_error: 106.5849\n",
      "Epoch 134/200\n",
      "331/331 [==============================] - 0s 53us/sample - loss: 105.6742 - mean_squared_error: 105.6742\n",
      "Epoch 135/200\n",
      "331/331 [==============================] - 0s 50us/sample - loss: 104.9057 - mean_squared_error: 104.9057\n",
      "Epoch 136/200\n",
      "331/331 [==============================] - 0s 54us/sample - loss: 104.2231 - mean_squared_error: 104.2231\n",
      "Epoch 137/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "331/331 [==============================] - 0s 47us/sample - loss: 103.4712 - mean_squared_error: 103.4712\n",
      "Epoch 138/200\n",
      "331/331 [==============================] - 0s 48us/sample - loss: 102.7470 - mean_squared_error: 102.7470\n",
      "Epoch 139/200\n",
      "331/331 [==============================] - 0s 37us/sample - loss: 102.0479 - mean_squared_error: 102.0479\n",
      "Epoch 140/200\n",
      "331/331 [==============================] - 0s 45us/sample - loss: 101.3745 - mean_squared_error: 101.3745\n",
      "Epoch 141/200\n",
      "331/331 [==============================] - 0s 38us/sample - loss: 100.7371 - mean_squared_error: 100.7371\n",
      "Epoch 142/200\n",
      "331/331 [==============================] - 0s 42us/sample - loss: 100.0252 - mean_squared_error: 100.0252\n",
      "Epoch 143/200\n",
      "331/331 [==============================] - 0s 34us/sample - loss: 99.2936 - mean_squared_error: 99.2937\n",
      "Epoch 144/200\n",
      "331/331 [==============================] - 0s 40us/sample - loss: 98.5953 - mean_squared_error: 98.5952\n",
      "Epoch 145/200\n",
      "331/331 [==============================] - 0s 36us/sample - loss: 97.8522 - mean_squared_error: 97.8522\n",
      "Epoch 146/200\n",
      "331/331 [==============================] - 0s 42us/sample - loss: 97.1094 - mean_squared_error: 97.1094\n",
      "Epoch 147/200\n",
      "331/331 [==============================] - 0s 42us/sample - loss: 96.5145 - mean_squared_error: 96.5145\n",
      "Epoch 148/200\n",
      "331/331 [==============================] - 0s 44us/sample - loss: 95.8891 - mean_squared_error: 95.8891\n",
      "Epoch 149/200\n",
      "331/331 [==============================] - 0s 40us/sample - loss: 95.4047 - mean_squared_error: 95.4047\n",
      "Epoch 150/200\n",
      "331/331 [==============================] - 0s 47us/sample - loss: 94.8823 - mean_squared_error: 94.8823\n",
      "Epoch 151/200\n",
      "331/331 [==============================] - 0s 53us/sample - loss: 94.3793 - mean_squared_error: 94.3793\n",
      "Epoch 152/200\n",
      "331/331 [==============================] - 0s 42us/sample - loss: 93.8604 - mean_squared_error: 93.8604\n",
      "Epoch 153/200\n",
      "331/331 [==============================] - 0s 50us/sample - loss: 93.2976 - mean_squared_error: 93.2976\n",
      "Epoch 154/200\n",
      "331/331 [==============================] - 0s 54us/sample - loss: 92.6053 - mean_squared_error: 92.6052\n",
      "Epoch 155/200\n",
      "331/331 [==============================] - 0s 38us/sample - loss: 91.9304 - mean_squared_error: 91.9304\n",
      "Epoch 156/200\n",
      "331/331 [==============================] - 0s 46us/sample - loss: 91.3552 - mean_squared_error: 91.3552\n",
      "Epoch 157/200\n",
      "331/331 [==============================] - 0s 43us/sample - loss: 90.8478 - mean_squared_error: 90.8478\n",
      "Epoch 158/200\n",
      "331/331 [==============================] - 0s 49us/sample - loss: 90.3326 - mean_squared_error: 90.3326\n",
      "Epoch 159/200\n",
      "331/331 [==============================] - 0s 52us/sample - loss: 89.9395 - mean_squared_error: 89.9395\n",
      "Epoch 160/200\n",
      "331/331 [==============================] - 0s 44us/sample - loss: 89.4274 - mean_squared_error: 89.4274\n",
      "Epoch 161/200\n",
      "331/331 [==============================] - 0s 47us/sample - loss: 89.0828 - mean_squared_error: 89.0828\n",
      "Epoch 162/200\n",
      "331/331 [==============================] - 0s 42us/sample - loss: 88.6273 - mean_squared_error: 88.6273\n",
      "Epoch 163/200\n",
      "331/331 [==============================] - 0s 44us/sample - loss: 88.2188 - mean_squared_error: 88.2188\n",
      "Epoch 164/200\n",
      "331/331 [==============================] - 0s 40us/sample - loss: 87.7796 - mean_squared_error: 87.7796\n",
      "Epoch 165/200\n",
      "331/331 [==============================] - 0s 53us/sample - loss: 87.3467 - mean_squared_error: 87.3467\n",
      "Epoch 166/200\n",
      "331/331 [==============================] - 0s 40us/sample - loss: 86.9373 - mean_squared_error: 86.9373\n",
      "Epoch 167/200\n",
      "331/331 [==============================] - 0s 42us/sample - loss: 86.5026 - mean_squared_error: 86.5026\n",
      "Epoch 168/200\n",
      "331/331 [==============================] - 0s 30us/sample - loss: 86.1049 - mean_squared_error: 86.1049\n",
      "Epoch 169/200\n",
      "331/331 [==============================] - 0s 44us/sample - loss: 85.6337 - mean_squared_error: 85.6337\n",
      "Epoch 170/200\n",
      "331/331 [==============================] - 0s 38us/sample - loss: 85.2357 - mean_squared_error: 85.2357\n",
      "Epoch 171/200\n",
      "331/331 [==============================] - 0s 37us/sample - loss: 84.8462 - mean_squared_error: 84.8462\n",
      "Epoch 172/200\n",
      "331/331 [==============================] - 0s 39us/sample - loss: 84.4879 - mean_squared_error: 84.4879\n",
      "Epoch 173/200\n",
      "331/331 [==============================] - 0s 31us/sample - loss: 84.0832 - mean_squared_error: 84.0832\n",
      "Epoch 174/200\n",
      "331/331 [==============================] - 0s 47us/sample - loss: 83.7238 - mean_squared_error: 83.7238\n",
      "Epoch 175/200\n",
      "331/331 [==============================] - 0s 32us/sample - loss: 83.3610 - mean_squared_error: 83.3610\n",
      "Epoch 176/200\n",
      "331/331 [==============================] - 0s 45us/sample - loss: 82.9931 - mean_squared_error: 82.9931\n",
      "Epoch 177/200\n",
      "331/331 [==============================] - 0s 36us/sample - loss: 82.6741 - mean_squared_error: 82.6741\n",
      "Epoch 178/200\n",
      "331/331 [==============================] - 0s 36us/sample - loss: 82.3050 - mean_squared_error: 82.3050\n",
      "Epoch 179/200\n",
      "331/331 [==============================] - 0s 42us/sample - loss: 81.9555 - mean_squared_error: 81.9555\n",
      "Epoch 180/200\n",
      "331/331 [==============================] - 0s 33us/sample - loss: 81.6818 - mean_squared_error: 81.6818\n",
      "Epoch 181/200\n",
      "331/331 [==============================] - 0s 36us/sample - loss: 81.3374 - mean_squared_error: 81.3374\n",
      "Epoch 182/200\n",
      "331/331 [==============================] - 0s 35us/sample - loss: 80.9451 - mean_squared_error: 80.9451\n",
      "Epoch 183/200\n",
      "331/331 [==============================] - 0s 47us/sample - loss: 80.6409 - mean_squared_error: 80.6409\n",
      "Epoch 184/200\n",
      "331/331 [==============================] - 0s 31us/sample - loss: 80.3166 - mean_squared_error: 80.3166\n",
      "Epoch 185/200\n",
      "331/331 [==============================] - 0s 46us/sample - loss: 80.0660 - mean_squared_error: 80.0660\n",
      "Epoch 186/200\n",
      "331/331 [==============================] - 0s 36us/sample - loss: 79.8126 - mean_squared_error: 79.8126\n",
      "Epoch 187/200\n",
      "331/331 [==============================] - 0s 50us/sample - loss: 79.5375 - mean_squared_error: 79.5375\n",
      "Epoch 188/200\n",
      "331/331 [==============================] - 0s 49us/sample - loss: 79.0635 - mean_squared_error: 79.0635\n",
      "Epoch 189/200\n",
      "331/331 [==============================] - 0s 34us/sample - loss: 78.9836 - mean_squared_error: 78.9836\n",
      "Epoch 190/200\n",
      "331/331 [==============================] - 0s 45us/sample - loss: 78.7052 - mean_squared_error: 78.7052\n",
      "Epoch 191/200\n",
      "331/331 [==============================] - 0s 48us/sample - loss: 78.4261 - mean_squared_error: 78.4261\n",
      "Epoch 192/200\n",
      "331/331 [==============================] - 0s 37us/sample - loss: 78.0932 - mean_squared_error: 78.0931\n",
      "Epoch 193/200\n",
      "331/331 [==============================] - 0s 35us/sample - loss: 77.7767 - mean_squared_error: 77.7767\n",
      "Epoch 194/200\n",
      "331/331 [==============================] - 0s 35us/sample - loss: 77.6521 - mean_squared_error: 77.6521\n",
      "Epoch 195/200\n",
      "331/331 [==============================] - 0s 34us/sample - loss: 77.3590 - mean_squared_error: 77.3590\n",
      "Epoch 196/200\n",
      "331/331 [==============================] - 0s 40us/sample - loss: 77.0856 - mean_squared_error: 77.0856\n",
      "Epoch 197/200\n",
      "331/331 [==============================] - 0s 41us/sample - loss: 76.8654 - mean_squared_error: 76.8654\n",
      "Epoch 198/200\n",
      "331/331 [==============================] - 0s 36us/sample - loss: 76.6355 - mean_squared_error: 76.6355\n",
      "Epoch 199/200\n",
      "331/331 [==============================] - 0s 33us/sample - loss: 76.4101 - mean_squared_error: 76.4101\n",
      "Epoch 200/200\n",
      "331/331 [==============================] - 0s 43us/sample - loss: 76.1819 - mean_squared_error: 76.1819\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=<tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x000001BE8798AB08>,\n",
       "             n_jobs=-1,\n",
       "             param_grid={'neuron_hidden_layer_1': [5, 6, 7],\n",
       "                         'neuron_hidden_layer_2': [2, 3, 4, 5]},\n",
       "             scoring='neg_mean_squared_error')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Perceptron Neural Network\n",
    "#Parameter Tuning for Multi-layer Perceptron Neural Network\n",
    "\n",
    "param= {\n",
    "    'neuron_hidden_layer_1': [6,7],\n",
    "    'neuron_hidden_layer_2': [3,4, 5],\n",
    "}\n",
    "\n",
    "def createNN( neuron_hidden_layer_1 , neuron_hidden_layer_2 ):\n",
    "    \n",
    "    model = Sequential()\n",
    "    if neuron_hidden_layer_1 > neuron_hidden_layer_2:\n",
    "        model.add(Dense(units = neuron_hidden_layer_1, activation = 'relu', kernel_initializer = 'he_normal', input_shape = (scaled_X.shape[1],)))\n",
    "        model.add(Dense(units =neuron_hidden_layer_2, activation = 'relu', kernel_initializer = 'he_normal'))\n",
    "        model.add(Dense(1))\n",
    "\n",
    "        model.compile(optimizer = 'adam' , loss = 'mse' , metrics= ['mse'])\n",
    "\n",
    "        return model\n",
    "\n",
    "#Define Grid Search\n",
    "model_wrapper = KerasRegressor(build_fn = createNN, batch_size= 30, epochs = 200)\n",
    "grid_search = GridSearchCV(model_wrapper, n_jobs=-1, cv=5, param_grid = param, scoring ='neg_mean_squared_error')\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec438848",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_neuron_hidden_layer_1</th>\n",
       "      <th>param_neuron_hidden_layer_2</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.831661</td>\n",
       "      <td>0.458719</td>\n",
       "      <td>0.130123</td>\n",
       "      <td>0.008548</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>{'neuron_hidden_layer_1': 5, 'neuron_hidden_la...</td>\n",
       "      <td>-91.675196</td>\n",
       "      <td>-83.442387</td>\n",
       "      <td>-71.534818</td>\n",
       "      <td>-56.561908</td>\n",
       "      <td>-152.274921</td>\n",
       "      <td>-91.097846</td>\n",
       "      <td>32.793344</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.630406</td>\n",
       "      <td>0.690460</td>\n",
       "      <td>0.156421</td>\n",
       "      <td>0.014534</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>{'neuron_hidden_layer_1': 5, 'neuron_hidden_la...</td>\n",
       "      <td>-71.639876</td>\n",
       "      <td>-93.896000</td>\n",
       "      <td>-63.033183</td>\n",
       "      <td>-108.330449</td>\n",
       "      <td>-137.525853</td>\n",
       "      <td>-94.885072</td>\n",
       "      <td>26.664113</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.268928</td>\n",
       "      <td>0.115779</td>\n",
       "      <td>0.153996</td>\n",
       "      <td>0.004724</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>{'neuron_hidden_layer_1': 5, 'neuron_hidden_la...</td>\n",
       "      <td>-70.227250</td>\n",
       "      <td>-79.856283</td>\n",
       "      <td>-80.260501</td>\n",
       "      <td>-64.335232</td>\n",
       "      <td>-151.600851</td>\n",
       "      <td>-89.256023</td>\n",
       "      <td>31.746786</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000904</td>\n",
       "      <td>0.000494</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>{'neuron_hidden_layer_1': 5, 'neuron_hidden_la...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.104713</td>\n",
       "      <td>0.072754</td>\n",
       "      <td>0.156449</td>\n",
       "      <td>0.001544</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>{'neuron_hidden_layer_1': 6, 'neuron_hidden_la...</td>\n",
       "      <td>-61.952153</td>\n",
       "      <td>-86.599543</td>\n",
       "      <td>-68.012073</td>\n",
       "      <td>-96.550494</td>\n",
       "      <td>-112.593274</td>\n",
       "      <td>-85.141507</td>\n",
       "      <td>18.531347</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.464538</td>\n",
       "      <td>0.390196</td>\n",
       "      <td>0.159523</td>\n",
       "      <td>0.022466</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>{'neuron_hidden_layer_1': 6, 'neuron_hidden_la...</td>\n",
       "      <td>-70.567014</td>\n",
       "      <td>-77.732816</td>\n",
       "      <td>-61.191302</td>\n",
       "      <td>-57.609641</td>\n",
       "      <td>-134.187481</td>\n",
       "      <td>-80.257651</td>\n",
       "      <td>27.875322</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6.428848</td>\n",
       "      <td>0.154658</td>\n",
       "      <td>0.182941</td>\n",
       "      <td>0.003650</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>{'neuron_hidden_layer_1': 6, 'neuron_hidden_la...</td>\n",
       "      <td>-68.718908</td>\n",
       "      <td>-69.743638</td>\n",
       "      <td>-72.077195</td>\n",
       "      <td>-79.872952</td>\n",
       "      <td>-133.973398</td>\n",
       "      <td>-84.877218</td>\n",
       "      <td>24.857330</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.696893</td>\n",
       "      <td>0.139940</td>\n",
       "      <td>0.173848</td>\n",
       "      <td>0.018760</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>{'neuron_hidden_layer_1': 6, 'neuron_hidden_la...</td>\n",
       "      <td>-66.350129</td>\n",
       "      <td>-77.599760</td>\n",
       "      <td>-61.041552</td>\n",
       "      <td>-72.494382</td>\n",
       "      <td>-149.904111</td>\n",
       "      <td>-85.477987</td>\n",
       "      <td>32.693670</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5.930898</td>\n",
       "      <td>0.610620</td>\n",
       "      <td>0.208968</td>\n",
       "      <td>0.007604</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>{'neuron_hidden_layer_1': 7, 'neuron_hidden_la...</td>\n",
       "      <td>-67.385927</td>\n",
       "      <td>-99.974248</td>\n",
       "      <td>-63.695949</td>\n",
       "      <td>-89.656187</td>\n",
       "      <td>-138.184417</td>\n",
       "      <td>-91.779346</td>\n",
       "      <td>26.865632</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6.739402</td>\n",
       "      <td>1.172384</td>\n",
       "      <td>0.208142</td>\n",
       "      <td>0.015428</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>{'neuron_hidden_layer_1': 7, 'neuron_hidden_la...</td>\n",
       "      <td>-62.452845</td>\n",
       "      <td>-68.230056</td>\n",
       "      <td>-68.684600</td>\n",
       "      <td>-80.607825</td>\n",
       "      <td>-147.433647</td>\n",
       "      <td>-85.481795</td>\n",
       "      <td>31.533754</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>7.149924</td>\n",
       "      <td>1.665362</td>\n",
       "      <td>0.162856</td>\n",
       "      <td>0.003836</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>{'neuron_hidden_layer_1': 7, 'neuron_hidden_la...</td>\n",
       "      <td>-1419.207821</td>\n",
       "      <td>-86.898034</td>\n",
       "      <td>-60.730461</td>\n",
       "      <td>-66.753418</td>\n",
       "      <td>-141.089351</td>\n",
       "      <td>-354.935817</td>\n",
       "      <td>532.889360</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4.789009</td>\n",
       "      <td>0.317693</td>\n",
       "      <td>0.105347</td>\n",
       "      <td>0.013065</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>{'neuron_hidden_layer_1': 7, 'neuron_hidden_la...</td>\n",
       "      <td>-63.071230</td>\n",
       "      <td>-91.360224</td>\n",
       "      <td>-73.511772</td>\n",
       "      <td>-82.737247</td>\n",
       "      <td>-140.500962</td>\n",
       "      <td>-90.236287</td>\n",
       "      <td>26.839099</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        6.831661      0.458719         0.130123        0.008548   \n",
       "1        5.630406      0.690460         0.156421        0.014534   \n",
       "2        5.268928      0.115779         0.153996        0.004724   \n",
       "3        0.000904      0.000494         0.000000        0.000000   \n",
       "4        5.104713      0.072754         0.156449        0.001544   \n",
       "5        5.464538      0.390196         0.159523        0.022466   \n",
       "6        6.428848      0.154658         0.182941        0.003650   \n",
       "7        5.696893      0.139940         0.173848        0.018760   \n",
       "8        5.930898      0.610620         0.208968        0.007604   \n",
       "9        6.739402      1.172384         0.208142        0.015428   \n",
       "10       7.149924      1.665362         0.162856        0.003836   \n",
       "11       4.789009      0.317693         0.105347        0.013065   \n",
       "\n",
       "   param_neuron_hidden_layer_1 param_neuron_hidden_layer_2  \\\n",
       "0                            5                           2   \n",
       "1                            5                           3   \n",
       "2                            5                           4   \n",
       "3                            5                           5   \n",
       "4                            6                           2   \n",
       "5                            6                           3   \n",
       "6                            6                           4   \n",
       "7                            6                           5   \n",
       "8                            7                           2   \n",
       "9                            7                           3   \n",
       "10                           7                           4   \n",
       "11                           7                           5   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'neuron_hidden_layer_1': 5, 'neuron_hidden_la...         -91.675196   \n",
       "1   {'neuron_hidden_layer_1': 5, 'neuron_hidden_la...         -71.639876   \n",
       "2   {'neuron_hidden_layer_1': 5, 'neuron_hidden_la...         -70.227250   \n",
       "3   {'neuron_hidden_layer_1': 5, 'neuron_hidden_la...                NaN   \n",
       "4   {'neuron_hidden_layer_1': 6, 'neuron_hidden_la...         -61.952153   \n",
       "5   {'neuron_hidden_layer_1': 6, 'neuron_hidden_la...         -70.567014   \n",
       "6   {'neuron_hidden_layer_1': 6, 'neuron_hidden_la...         -68.718908   \n",
       "7   {'neuron_hidden_layer_1': 6, 'neuron_hidden_la...         -66.350129   \n",
       "8   {'neuron_hidden_layer_1': 7, 'neuron_hidden_la...         -67.385927   \n",
       "9   {'neuron_hidden_layer_1': 7, 'neuron_hidden_la...         -62.452845   \n",
       "10  {'neuron_hidden_layer_1': 7, 'neuron_hidden_la...       -1419.207821   \n",
       "11  {'neuron_hidden_layer_1': 7, 'neuron_hidden_la...         -63.071230   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0          -83.442387         -71.534818         -56.561908   \n",
       "1          -93.896000         -63.033183        -108.330449   \n",
       "2          -79.856283         -80.260501         -64.335232   \n",
       "3                 NaN                NaN                NaN   \n",
       "4          -86.599543         -68.012073         -96.550494   \n",
       "5          -77.732816         -61.191302         -57.609641   \n",
       "6          -69.743638         -72.077195         -79.872952   \n",
       "7          -77.599760         -61.041552         -72.494382   \n",
       "8          -99.974248         -63.695949         -89.656187   \n",
       "9          -68.230056         -68.684600         -80.607825   \n",
       "10         -86.898034         -60.730461         -66.753418   \n",
       "11         -91.360224         -73.511772         -82.737247   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0         -152.274921       -91.097846       32.793344                8  \n",
       "1         -137.525853       -94.885072       26.664113               10  \n",
       "2         -151.600851       -89.256023       31.746786                6  \n",
       "3                 NaN              NaN             NaN               12  \n",
       "4         -112.593274       -85.141507       18.531347                3  \n",
       "5         -134.187481       -80.257651       27.875322                1  \n",
       "6         -133.973398       -84.877218       24.857330                2  \n",
       "7         -149.904111       -85.477987       32.693670                4  \n",
       "8         -138.184417       -91.779346       26.865632                9  \n",
       "9         -147.433647       -85.481795       31.533754                5  \n",
       "10        -141.089351      -354.935817      532.889360               11  \n",
       "11        -140.500962       -90.236287       26.839099                7  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ecaeaa64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi-layer Perceptron Neural Network best Params: {'neuron_hidden_layer_1': 6, 'neuron_hidden_layer_2': 3}\n",
      "Multi-layer Perceptron Neural Network best Score: -80.25765072978587\n"
     ]
    }
   ],
   "source": [
    "#Summarize Results of model with best parameter and its score \n",
    "print('Multi-layer Perceptron Neural Network best Params:', grid_search.best_params_)\n",
    "print('Multi-layer Perceptron Neural Network best Score:', grid_search.best_score_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
